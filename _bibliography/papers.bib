---
---

@article{j.asr.2024.02.048,
title = {Deep learning-assisted near-Earth asteroid tracking in astronomical images},
journal = {Advances in Space Research},
abbr={ASR},
volume = {73},
number = {10},
pages = {5349-5362},
year = {2024},
issn = {0273-1177},
doi = {https://doi.org/10.1016/j.asr.2024.02.048},
url = {https://www.sciencedirect.com/science/article/pii/S0273117724001911},
author = {Zhenhong Du and Hai Jiang and Xu Yang and Hao-Wen Cheng and Jing Liu},
keywords = {Near-Earth asteroid, Deep learning, Convolutional neural network, Faint object extraction, Moving object linking},
abstract = {The large number of near-Earth asteroids (NEAs) has greatly impacted human space activities and Earth security. However, detecting NEAs in astronomical images with complex, varying backgrounds is still extremely challenging. In this paper, we propose a deep segmentation assisted asteroid tracking algorithm, termed DSAT, to construct a possible pipeline for faint NEA tracking in astronomical images. First, the single-frame object detection problem is converted to a segmentation problem, enabling robust extraction of faint potential moving objects. Then, a multiframe motion prior-based moving object tracking algorithm is proposed to find real NEAs. We further propose a distance tolerance criterion to help DSAT achieve effective tracking in practical situations when detection has partially failed. Finally, the pipeline is tested with both simulated and real astronomical images at different SNRs and in crowded fields. The results showed that our pipeline has the potential to detect and track faint NEAs in complex backgrounds. Our code is publicly available at https://github.com/zhenhongdu/DeepSegAsteroidTracker.}
}


@article{10.3389/fphy.2022.965095,
AUTHOR={Chen*, Jiajia and Du*, Zhenhong and Si, Ke},   
	 
TITLE={Three-Dimensional Virtual Optical Clearing With Cycle-Consistent Generative Adversarial Network},      
	
JOURNAL={Frontiers in Physics},      
	
VOLUME={10},           
	
YEAR={2022},      
	  
URL={https://www.frontiersin.org/articles/10.3389/fphy.2022.965095},       
	
DOI={10.3389/fphy.2022.965095},      
	
ISSN={2296-424X},   
   
ABSTRACT={High-throughput deep tissue imaging and chemical tissue clearing protocols have brought out great promotion in biological research. However, due to uneven transparency introduced by tissue anisotropy in imperfectly cleared tissues, fluorescence imaging based on direct chemical tissue clearing still encounters great challenges, such as image blurring, low contrast, artifacts and so on. Here we reported a three-dimensional virtual optical clearing method based on unsupervised cycle-consistent generative adversarial network, termed 3D-VoCycleGAN, to digitally improve image quality and tissue transparency of biological samples. We demonstrated the good image deblurring and denoising capability of our method on imperfectly cleared mouse brain and kidney tissues. With 3D-VoCycleGAN prediction, the signal-to-background ratio (SBR) of images in imperfectly cleared brain tissue areas also showed above 40% improvement. Compared to other deconvolution methods, our method could evidently eliminate the tissue opaqueness and restore the image quality of the larger 3D images deep inside the imperfect cleared biological tissues with higher efficiency. And after virtually cleared, the transparency and clearing depth of mouse kidney tissues were increased by up to 30%. To our knowledge, it is the first interdisciplinary application of the CycleGAN deep learning model in the 3D fluorescence imaging and tissue clearing fields, promoting the development of high-throughput volumetric fluorescence imaging and deep learning techniques.}
}